import gradio as gr
import whisper
import tempfile
import os
from datetime import datetime, timedelta

# åŠ è½½ Whisper æ¨¡å‹
model = whisper.load_model("medium", download_root="models")

def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
    td = timedelta(seconds=seconds)
    hours, remainder = divmod(td.total_seconds(), 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = int((seconds % 1) * 1000)
    return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"

def generate_srt(segments):
    """ç”Ÿæˆ SRT å­—å¹•æ ¼å¼"""
    srt_content = ""
    for i, segment in enumerate(segments, 1):
        start_time = format_timestamp(segment['start'])
        end_time = format_timestamp(segment['end'])
        text = segment['text'].strip()
        srt_content += f"{i}\n{start_time} --> {end_time}\n{text}\n\n"
    return srt_content

def transcribe_audio(audio_file):
    """è½¬å½•éŸ³é¢‘å¹¶ç”Ÿæˆå­—å¹•æ–‡ä»¶"""
    if audio_file is None:
        return [], None
    
    try:
        # è½¬å½•éŸ³é¢‘
        result = model.transcribe(audio_file)
        
        # ç”Ÿæˆè¡¨æ ¼æ•°æ®
        table_data = []
        for segment in result['segments']:
            start_time = format_timestamp(segment['start'])
            end_time = format_timestamp(segment['end'])
            duration = segment['end'] - segment['start']
            duration_str = f"{duration:.1f}s"
            text = segment['text'].strip()
            char_count = len(text)
            confidence = f"{(1 - segment.get('no_speech_prob', 0)) * 100:.1f}%"
            table_data.append([segment['id'], start_time, end_time, duration_str, char_count, confidence, text])
        
        # ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
        subtitle_content = generate_srt(result['segments'])
        
        # ç”Ÿæˆæœ‰æ„ä¹‰çš„æ–‡ä»¶å
        audio_filename = os.path.basename(audio_file)
        audio_name = os.path.splitext(audio_filename)[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        subtitle_filename = f"{audio_name}_{timestamp}.srt"
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8') as f:
            f.write(subtitle_content)
            subtitle_file_path = f.name
        
        # é‡å‘½åæ–‡ä»¶ä¸ºæœ‰æ„ä¹‰çš„åç§°
        final_path = os.path.join(os.path.dirname(subtitle_file_path), subtitle_filename)
        os.rename(subtitle_file_path, final_path)
        subtitle_file_path = final_path
        
        return table_data, subtitle_file_path
    
    except Exception as e:
        return [], None

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="è¯­éŸ³å­—å¹•æå–å™¨") as demo:
    gr.Markdown("# ğŸµ è¯­éŸ³å­—å¹•æå–å™¨")
    gr.Markdown("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œè‡ªåŠ¨æå–è¯­éŸ³å¹¶ç”Ÿæˆå­—å¹•æ–‡ä»¶")
    
    # ä¸Šä¼ åŒºåŸŸ
    audio_input = gr.Audio(
        label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
        type="filepath",
        sources=["upload"]
    )
    
    submit_btn = gr.Button("å¼€å§‹è½¬å½•", variant="primary", size="lg")
    
    # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
    output_table = gr.DataFrame(
        label="è½¬å½•ç»“æœ",
        headers=["åºå·", "å¼€å§‹æ—¶é—´", "ç»“æŸæ—¶é—´", "æ—¶é•¿", "å­—ç¬¦æ•°", "ç½®ä¿¡åº¦", "æ–‡æœ¬å†…å®¹"],
        datatype=["number", "str", "str", "str", "number", "str", "str"],
        interactive=False,
        wrap=True
    )
    
    download_file = gr.File(
        label="ä¸‹è½½å­—å¹•æ–‡ä»¶"
    )
    
    # ç»‘å®šäº‹ä»¶
    submit_btn.click(
        fn=transcribe_audio,
        inputs=[audio_input],
        outputs=[output_table, download_file]
    )
    
    gr.Markdown("### ä½¿ç”¨è¯´æ˜")
    gr.Markdown("""
    1. ç‚¹å‡»ä¸Šä¼ åŒºåŸŸé€‰æ‹©éŸ³é¢‘æ–‡ä»¶
    2. ç‚¹å‡»"å¼€å§‹è½¬å½•"æŒ‰é’®
    3. ç­‰å¾…å¤„ç†å®ŒæˆåæŸ¥çœ‹ç»“æœå’Œä¸‹è½½ SRT å­—å¹•æ–‡ä»¶
    
    **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**: MP3, WAV, FLAC, AAC, OGG ç­‰å¸¸è§éŸ³é¢‘æ ¼å¼
    """)

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)